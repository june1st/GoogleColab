{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/june1st/GoogleColab/blob/master/MirrorGAN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRaP4oWerC35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9c98901e-0677-41af-b574-59e43a911c59"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May  7 07:17:09 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3OE6O_4bB7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ccf389c9-3629-4f4f-f79a-ad6fe4607a22"
      },
      "source": [
        "!git clone https://github.com/komiya-m/MirrorGAN\n",
        "%cd MirrorGAN"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MirrorGAN'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 71 (delta 32), reused 54 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n",
            "/content/MirrorGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywH_tRetcfnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4dd21038-81c2-4206-be1b-268e8e386073"
      },
      "source": [
        "!mkdir data\n",
        "%cd data\n",
        "#https://drive.google.com/open?id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
        "%env FILE_ID=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
        "%env FILE_NAME=birds.zip\n",
        "!curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=${FILE_ID}\" > /dev/null\n",
        "!awk '/_warning_/ {print $NF}' /tmp/cookie > ./code.txt\n",
        "\n",
        "test_data = open(\"code.txt\", \"r\")\n",
        "code = test_data.read().replace('\\n','')\n",
        "test_data.close()\n",
        "\n",
        "import os\n",
        "os.environ[\"CODE\"] =code\n",
        "!echo $CODE\n",
        "!curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=${CODE}&id=${FILE_ID}\" -o ${FILE_NAME}\n",
        "\n",
        "#Download Images\n",
        "!unzip birds.zip > /dev/null\n",
        "%cd birds \n",
        "!wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
        "!tar -zxvf CUB_200_2011.tgz > /dev/null\n",
        "%cd /content/MirrorGAN"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MirrorGAN/data\n",
            "env: FILE_ID=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "env: FILE_NAME=birds.zip\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0     21      0 --:--:--  0:00:17 --:--:--    83\n",
            "100 6336k    0 6336k    0     0   349k      0 --:--:--  0:00:18 --:--:-- 71.1M\n",
            "/content/MirrorGAN/data/birds\n",
            "--2019-05-07 07:18:23--  http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
            "Resolving www.vision.caltech.edu (www.vision.caltech.edu)... 34.208.54.77\n",
            "Connecting to www.vision.caltech.edu (www.vision.caltech.edu)|34.208.54.77|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1150585339 (1.1G) [application/x-tar]\n",
            "Saving to: ‘CUB_200_2011.tgz’\n",
            "\n",
            "CUB_200_2011.tgz    100%[===================>]   1.07G  8.21MB/s    in 2m 7s   \n",
            "\n",
            "2019-05-07 07:20:31 (8.64 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
            "\n",
            "/content/MirrorGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eMbF0Skbjz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cat config.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8erDcXubn85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31b06f2f-97cf-421f-fc45-dc2b4b19b6f1"
      },
      "source": [
        "%%writefile config.py\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "\n",
        "__C = edict()\n",
        "cfg = __C\n",
        "\n",
        "# Dataset name: flowers, birds\n",
        "__C.DATASET_NAME = 'birds'\n",
        "__C.CONFIG_NAME = ''\n",
        "__C.DATA_DIR = 'data/birds'\n",
        "\n",
        "__C.RNN_TYPE = 'gru'  # 'lstm'\n",
        "\n",
        "__C.TREE = edict()\n",
        "__C.TREE.BRANCH_NUM = 3#1\n",
        "__C.TREE.BASE_SIZE = 64\n",
        "\n",
        "# Training options\n",
        "__C.TRAIN = edict()\n",
        "__C.TRAIN.BATCH_SIZE = 20\n",
        "__C.TRAIN.MAX_EPOCH = 1\n",
        "__C.TRAIN.FLAG = True\n",
        "#loadするモデルのpath（重みのみ）\n",
        "__C.TRAIN.NET_D = ''\n",
        "__C.TRAIN.INIT_NET_G = ''\n",
        "__C.TRAIN.NEXT128_NET_G = ''\n",
        "__C.TRAIN.NEXT256_NET_G = ''\n",
        "__C.TRAIN.RNN_DEC = ''#'model/cnn_rnn_encoder02_2.h5'\n",
        "\n",
        "__C.TRAIN.D_LR = 0.0001 #Dのラーニングレート\n",
        "__C.TRAIN.D_BETA1 = 0.5 #ADAM, beta1\n",
        "__C.TRAIN.G_LR = 0.0004 #Gのラーニングレート\n",
        "__C.TRAIN.G_BETA1 = 0.5 #ADAM, beta1\n",
        "__C.TRAIN.RNN_DEC_LOSS_W = 0.1  #デコーダーRNNのloss_weight\n",
        "\n",
        "__C.TRAIN.DEC_LR = 0.001  #pretrainのデコーダーRNNのラーニングレート\n",
        "__C.TRAIN.DEC_SAVE_PATH = 'model/cnn_rnn_encoder.h5'\n",
        "__C.TRAIN.DEC_MAX_EPOCH = 10\n",
        "\n",
        "# Modal options\n",
        "__C.GAN = edict()\n",
        "__C.GAN.DF_DIM = 64\n",
        "__C.GAN.GF_DIM = 128\n",
        "__C.GAN.Z_DIM = 100\n",
        "__C.GAN.CONDITION_DIM = 100\n",
        "__C.GAN.R_NUM = 2\n",
        "__C.GAN.B_ATTENTION = True\n",
        "__C.GAN.B_DCGAN = False\n",
        "\n",
        "\n",
        "__C.TEXT = edict()\n",
        "__C.TEXT.CAPTIONS_PER_IMAGE = 10\n",
        "__C.TEXT.EMBEDDING_DIM = 256\n",
        "####追加\n",
        "__C.TEXT.EMBEDDING_DIM_DEC = 512\n",
        "__C.TEXT.HIDDEN_DIM = 256\n",
        "####追加\n",
        "__C.TEXT.HIDDEN_DIM_DEC = 512\n",
        "__C.TEXT.WORDS_NUM = 18\n",
        "\n",
        "\n",
        "def _merge_a_into_b(a, b):\n",
        "    \"\"\"Merge config dictionary a into config dictionary b, clobbering the\n",
        "    options in b whenever they are also specified in a.\n",
        "    \"\"\"\n",
        "    if type(a) is not edict:\n",
        "        return\n",
        "\n",
        "    for k, v in a.items():  #変更python3\n",
        "        # a must specify keys that are in b\n",
        "        if not k in b: #変更python3\n",
        "            raise KeyError('{} is not a valid config key'.format(k))\n",
        "\n",
        "        # the types must match, too\n",
        "        old_type = type(b[k])\n",
        "        if old_type is not type(v):\n",
        "            if isinstance(b[k], np.ndarray):\n",
        "                v = np.array(v, dtype=b[k].dtype)\n",
        "            else:\n",
        "                raise ValueError(('Type mismatch ({} vs. {}) '\n",
        "                                  'for config key: {}').format(type(b[k]),\n",
        "                                                               type(v), k))\n",
        "\n",
        "        # recursively merge dicts\n",
        "        if type(v) is edict:\n",
        "            try:\n",
        "                _merge_a_into_b(a[k], b[k])\n",
        "            except:\n",
        "                print('Error under config key: {}'.format(k))\n",
        "                raise\n",
        "        else:\n",
        "            b[k] = v\n",
        "\n",
        "\n",
        "def cfg_from_file(filename):\n",
        "    \"\"\"Load a config file and merge it into the default options.\"\"\"\n",
        "    import yaml\n",
        "    with open(filename, 'r') as f:\n",
        "        yaml_cfg = edict(yaml.load(f))\n",
        "\n",
        "    _merge_a_into_b(yaml_cfg, __C)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting config.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuVZs2zxv279",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQWJgtrY1Rgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "11003833-e6f1-4e57-d0b6-c5e845ca9b20"
      },
      "source": [
        "run pretrain_STREAM.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: data/birds/test/filenames.pickle (2933)\n",
            "Load from:  data/birds/captions.pickle\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: data/birds/test/filenames.pickle (2933)\n",
            "Load from:  data/birds/captions.pickle\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cr_pic_input (InputLayer)       (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 299, 299, 3)  0           cr_pic_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_v3 (Model)            (None, 2048)         21802784    lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          1049088     inception_v3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "cr_cap_input (InputLayer)       (None, 18)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 512)       0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 18, 512)      2790400     cr_cap_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 19, 512)      0           reshape_1[0][0]                  \n",
            "                                                                 embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (None, 19, 512)      1574400     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "CR_out_layre (Dense)            (None, 19, 5450)     2795850     gru_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 30,012,522\n",
            "Trainable params: 8,209,738\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/10\n",
            "442/442 [==============================] - 338s 765ms/step - loss: 2.6131 - acc: 0.4786 - val_loss: 2.0219 - val_acc: 0.5806\n",
            "Epoch 2/10\n",
            "442/442 [==============================] - 323s 730ms/step - loss: 1.8723 - acc: 0.5775 - val_loss: 1.8723 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "442/442 [==============================] - 319s 722ms/step - loss: 1.6891 - acc: 0.6014 - val_loss: 1.8518 - val_acc: 0.6041\n",
            "Epoch 4/10\n",
            "442/442 [==============================] - 318s 719ms/step - loss: 1.5803 - acc: 0.6163 - val_loss: 1.8345 - val_acc: 0.6101\n",
            "Epoch 5/10\n",
            " 86/442 [====>.........................] - ETA: 2:11 - loss: 1.5729 - acc: 0.6161"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkPLXY0hJoiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile config.py\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "\n",
        "__C = edict()\n",
        "cfg = __C\n",
        "\n",
        "# Dataset name: flowers, birds\n",
        "__C.DATASET_NAME = 'birds'\n",
        "__C.CONFIG_NAME = ''\n",
        "__C.DATA_DIR = 'data/birds'\n",
        "\n",
        "__C.RNN_TYPE = 'gru'  # 'lstm'\n",
        "\n",
        "__C.TREE = edict()\n",
        "__C.TREE.BRANCH_NUM = 1#1\n",
        "__C.TREE.BASE_SIZE = 64\n",
        "\n",
        "# Training options\n",
        "__C.TRAIN = edict()\n",
        "__C.TRAIN.BATCH_SIZE = 20\n",
        "__C.TRAIN.MAX_EPOCH = 1\n",
        "__C.TRAIN.FLAG = True\n",
        "#loadするモデルのpath（重みのみ）\n",
        "__C.TRAIN.NET_D = ''\n",
        "__C.TRAIN.INIT_NET_G = ''\n",
        "__C.TRAIN.NEXT128_NET_G = ''\n",
        "__C.TRAIN.NEXT256_NET_G = ''\n",
        "__C.TRAIN.RNN_DEC = 'model/cnn_rnn_encoder02_2.h5'\n",
        "\n",
        "__C.TRAIN.D_LR = 0.0001 #Dのラーニングレート\n",
        "__C.TRAIN.D_BETA1 = 0.5 #ADAM, beta1\n",
        "__C.TRAIN.G_LR = 0.0004 #Gのラーニングレート\n",
        "__C.TRAIN.G_BETA1 = 0.5 #ADAM, beta1\n",
        "__C.TRAIN.RNN_DEC_LOSS_W = 0.1  #デコーダーRNNのloss_weight\n",
        "\n",
        "__C.TRAIN.DEC_LR = 0.001  #pretrainのデコーダーRNNのラーニングレート\n",
        "__C.TRAIN.DEC_SAVE_PATH = 'model/cnn_rnn_encoder.h5'\n",
        "__C.TRAIN.DEC_MAX_EPOCH = 10\n",
        "\n",
        "# Modal options\n",
        "__C.GAN = edict()\n",
        "__C.GAN.DF_DIM = 64\n",
        "__C.GAN.GF_DIM = 128\n",
        "__C.GAN.Z_DIM = 100\n",
        "__C.GAN.CONDITION_DIM = 100\n",
        "__C.GAN.R_NUM = 2\n",
        "__C.GAN.B_ATTENTION = True\n",
        "__C.GAN.B_DCGAN = False\n",
        "\n",
        "\n",
        "__C.TEXT = edict()\n",
        "__C.TEXT.CAPTIONS_PER_IMAGE = 10\n",
        "__C.TEXT.EMBEDDING_DIM = 256\n",
        "####追加\n",
        "__C.TEXT.EMBEDDING_DIM_DEC = 512\n",
        "__C.TEXT.HIDDEN_DIM = 256\n",
        "####追加\n",
        "__C.TEXT.HIDDEN_DIM_DEC = 512\n",
        "__C.TEXT.WORDS_NUM = 18\n",
        "\n",
        "\n",
        "def _merge_a_into_b(a, b):\n",
        "    \"\"\"Merge config dictionary a into config dictionary b, clobbering the\n",
        "    options in b whenever they are also specified in a.\n",
        "    \"\"\"\n",
        "    if type(a) is not edict:\n",
        "        return\n",
        "\n",
        "    for k, v in a.items():  #変更python3\n",
        "        # a must specify keys that are in b\n",
        "        if not k in b: #変更python3\n",
        "            raise KeyError('{} is not a valid config key'.format(k))\n",
        "\n",
        "        # the types must match, too\n",
        "        old_type = type(b[k])\n",
        "        if old_type is not type(v):\n",
        "            if isinstance(b[k], np.ndarray):\n",
        "                v = np.array(v, dtype=b[k].dtype)\n",
        "            else:\n",
        "                raise ValueError(('Type mismatch ({} vs. {}) '\n",
        "                                  'for config key: {}').format(type(b[k]),\n",
        "                                                               type(v), k))\n",
        "\n",
        "        # recursively merge dicts\n",
        "        if type(v) is edict:\n",
        "            try:\n",
        "                _merge_a_into_b(a[k], b[k])\n",
        "            except:\n",
        "                print('Error under config key: {}'.format(k))\n",
        "                raise\n",
        "        else:\n",
        "            b[k] = v\n",
        "\n",
        "\n",
        "def cfg_from_file(filename):\n",
        "    \"\"\"Load a config file and merge it into the default options.\"\"\"\n",
        "    import yaml\n",
        "    with open(filename, 'r') as f:\n",
        "        yaml_cfg = edict(yaml.load(f))\n",
        "\n",
        "    _merge_a_into_b(yaml_cfg, __C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQhX4ezscK9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "a9ddaed5-509b-4701-8557-219def67c2a0"
      },
      "source": [
        "run train.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: data/birds/test/filenames.pickle (2933)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load from:  data/birds/captions.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loadmodel_completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/442 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch_size: 20  step_epoch : 442 srong_step_epoch 147\n",
            "----------------EPOCH: 0 START----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/content/MirrorGAN/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/MirrorGAN/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m                 histGRD = GRD_model.train_on_batch(\n\u001b[1;32m    140\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mcaptions_ar_prezeropad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions_ar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0;34m[\u001b[0m\u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 )\n\u001b[1;32m    143\u001b[0m             \u001b[0mtotal_G_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhistGRD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20,768,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/AddN_159-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_1/Discriminator_loss_1/Mean_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfMiVFCcSt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}